"""
Dynamic Biomarker Modeling Module

This module implements temporal trajectory analysis for biomarker validation,
incorporating intervention effects and recovery patterns for longitudinal analysis.

Key Features:
- Temporal trajectory modeling with intervention effects
- Recovery pattern analysis and prediction
- Longitudinal biomarker validation
- Dynamic risk scoring with time-dependent coefficients
- Treatment response modeling

Author: AI Pipeline Team
Date: September 2025
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import logging
from enum import Enum
import json
import warnings
from scipy import stats
from scipy.interpolate import interp1d
from scipy.optimize import minimize
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge
import joblib

# Configure logging
logger = logging.getLogger(__name__)

# Suppress sklearn warnings for cleaner output
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')


class TrajectoryType(Enum):
    """Types of biomarker trajectories"""
    LINEAR = "linear"
    EXPONENTIAL = "exponential"
    LOGISTIC = "logistic"
    POLYNOMIAL = "polynomial"
    PIECEWISE_LINEAR = "piecewise_linear"
    RECOVERY = "recovery"
    DECLINE_RECOVERY = "decline_recovery"


class InterventionType(Enum):
    """Types of interventions that can affect trajectories"""
    NONE = "none"
    TREATMENT = "treatment"
    SURGERY = "surgery"
    LIFESTYLE = "lifestyle"
    MEDICATION = "medication"
    COMBINATION = "combination"


class ModelType(Enum):
    """Types of temporal models"""
    LINEAR_MIXED = "linear_mixed"
    RANDOM_FOREST = "random_forest"
    GAUSSIAN_PROCESS = "gaussian_process"
    NEURAL_ODE = "neural_ode"
    SPLINE_REGRESSION = "spline_regression"


@dataclass
class TemporalDataPoint:
    """Single temporal measurement"""
    patient_id: str
    timepoint: float  # Time in hours/days from baseline
    biomarker_values: Dict[str, float]
    clinical_status: Dict[str, Any]
    intervention_status: Optional[InterventionType] = None
    intervention_time: Optional[float] = None
    measurement_quality: float = 1.0


@dataclass
class TrajectoryModel:
    """Model for biomarker trajectory"""
    trajectory_id: str
    biomarker_name: str
    trajectory_type: TrajectoryType
    model_type: ModelType
    parameters: Dict[str, float]
    fit_metrics: Dict[str, float]
    confidence_intervals: Dict[str, Tuple[float, float]]
    intervention_effects: Dict[InterventionType, Dict[str, float]]
    recovery_parameters: Optional[Dict[str, float]] = None
    prediction_horizon: float = 168.0  # 7 days default


@dataclass
class RecoveryPattern:
    """Recovery pattern after intervention"""
    pattern_id: str
    intervention_type: InterventionType
    baseline_trajectory: TrajectoryModel
    recovery_trajectory: TrajectoryModel
    transition_time: float
    recovery_rate: float
    plateau_value: Optional[float] = None
    recovery_success_probability: float = 0.0


class DynamicBiomarkerModeler:
    """
    Dynamic biomarker modeling for temporal trajectory analysis
    
    This class implements comprehensive temporal modeling capabilities for
    biomarker validation including intervention effects and recovery patterns.
    """
    
    def __init__(self, 
                 data_dir: Path,
                 output_dir: Path,
                 time_unit: str = "hours"):
        """
        Initialize dynamic biomarker modeler
        
        Args:
            data_dir: Directory containing temporal data
            output_dir: Directory for saving models and results
            time_unit: Unit for time measurements (hours, days, weeks)
        """
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.time_unit = time_unit
        
        # Create output directory
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Data storage
        self.temporal_data: List[TemporalDataPoint] = []
        self.trajectory_models: Dict[str, TrajectoryModel] = {}
        self.recovery_patterns: Dict[str, RecoveryPattern] = {}
        
        # Model storage
        self.fitted_models: Dict[str, Any] = {}
        self.scalers: Dict[str, StandardScaler] = {}
        
        logger.info(f"Initialized Dynamic Biomarker Modeler")
        logger.info(f"Data directory: {self.data_dir}")
        logger.info(f"Output directory: {self.output_dir}")
    
    def load_temporal_data(self, 
                          temporal_file: Path,
                          biomarker_columns: List[str],
                          time_column: str = "timepoint",
                          patient_column: str = "patient_id") -> pd.DataFrame:
        """Load temporal biomarker data"""
        
        logger.info(f"Loading temporal data from {temporal_file}")
        
        if temporal_file.exists():
            df = pd.read_csv(temporal_file)
        else:
            # Create demo temporal data
            logger.info("Creating demo temporal data")
            df = self._create_demo_temporal_data(biomarker_columns)
        
        # Convert to TemporalDataPoint objects
        self.temporal_data = []
        
        for _, row in df.iterrows():
            biomarker_values = {col: row[col] for col in biomarker_columns}
            clinical_status = {col: row[col] for col in df.columns 
                             if col not in [patient_column, time_column] + biomarker_columns}
            
            data_point = TemporalDataPoint(
                patient_id=str(row[patient_column]),
                timepoint=float(row[time_column]),
                biomarker_values=biomarker_values,
                clinical_status=clinical_status,
                intervention_status=InterventionType(row.get('intervention_type', 'none')),
                intervention_time=row.get('intervention_time'),
                measurement_quality=row.get('quality_score', 1.0)
            )
            
            self.temporal_data.append(data_point)
        
        logger.info(f"Loaded {len(self.temporal_data)} temporal measurements")
        logger.info(f"Biomarkers: {biomarker_columns}")
        
        return df
    
    def fit_trajectory_model(self,
                           biomarker_name: str,
                           trajectory_type: TrajectoryType = TrajectoryType.LINEAR,
                           model_type: ModelType = ModelType.RANDOM_FOREST,
                           include_interventions: bool = True) -> TrajectoryModel:
        """Fit temporal trajectory model for a biomarker"""
        
        logger.info(f"Fitting trajectory model for {biomarker_name}")
        logger.info(f"Trajectory type: {trajectory_type.value}")
        logger.info(f"Model type: {model_type.value}")
        
        # Extract data for this biomarker
        times, values, patient_ids, interventions = self._extract_biomarker_data(biomarker_name)
        
        if len(times) == 0:
            raise ValueError(f"No data found for biomarker {biomarker_name}")
        
        # Prepare features
        X = self._prepare_features(times, patient_ids, interventions if include_interventions else None)
        y = np.array(values)
        
        # Fit model based on type
        model, fit_metrics = self._fit_temporal_model(X, y, model_type)
        
        # Calculate confidence intervals
        confidence_intervals = self._calculate_confidence_intervals(model, X, y, model_type)
        
        # Analyze intervention effects
        intervention_effects = {}
        if include_interventions:
            intervention_effects = self._analyze_intervention_effects(
                biomarker_name, model, model_type
            )
        
        # Extract model parameters
        parameters = self._extract_model_parameters(model, model_type)
        
        # Create trajectory model
        trajectory_model = TrajectoryModel(
            trajectory_id=f"{biomarker_name}_{trajectory_type.value}",
            biomarker_name=biomarker_name,
            trajectory_type=trajectory_type,
            model_type=model_type,
            parameters=parameters,
            fit_metrics=fit_metrics,
            confidence_intervals=confidence_intervals,
            intervention_effects=intervention_effects
        )
        
        # Store model
        self.trajectory_models[trajectory_model.trajectory_id] = trajectory_model
        self.fitted_models[trajectory_model.trajectory_id] = model
        
        logger.info(f"Trajectory model fitted successfully")
        logger.info(f"R¬≤ score: {fit_metrics.get('r2_score', 'N/A'):.3f}")
        logger.info(f"RMSE: {fit_metrics.get('rmse', 'N/A'):.3f}")
        
        return trajectory_model
    
    def analyze_recovery_patterns(self,
                                biomarker_name: str,
                                intervention_type: InterventionType) -> RecoveryPattern:
        """Analyze recovery patterns after intervention"""
        
        logger.info(f"Analyzing recovery patterns for {biomarker_name}")
        logger.info(f"Intervention type: {intervention_type.value}")
        
        # Get pre and post intervention data
        pre_data, post_data = self._split_intervention_data(biomarker_name, intervention_type)
        
        if len(pre_data[0]) < 5 or len(post_data[0]) < 5:
            logger.warning("Insufficient data for recovery analysis")
            # Return dummy recovery pattern for insufficient data
            dummy_model = TrajectoryModel(
                trajectory_id=f"{biomarker_name}_dummy",
                biomarker_name=biomarker_name,
                trajectory_type=TrajectoryType.LINEAR,
                model_type=ModelType.LINEAR_MIXED,
                parameters={'slope': 0.0, 'intercept': 0.0},
                fit_metrics={'r2_score': 0.0, 'rmse': 0.0},
                confidence_intervals={'slope': (0.0, 0.0)},
                intervention_effects={}
            )
            return RecoveryPattern(
                pattern_id=f"{biomarker_name}_{intervention_type.value}_recovery",
                intervention_type=intervention_type,
                baseline_trajectory=dummy_model,
                recovery_trajectory=dummy_model,
                transition_time=0.0,
                recovery_rate=0.0,
                recovery_success_probability=0.0
            )
        
        # Fit baseline trajectory (pre-intervention)
        baseline_model = self._fit_baseline_trajectory(pre_data, biomarker_name)
        
        # Fit recovery trajectory (post-intervention)  
        recovery_model = self._fit_recovery_trajectory(post_data, biomarker_name)
        
        # Calculate recovery metrics
        recovery_rate = self._calculate_recovery_rate(post_data)
        transition_time = self._estimate_transition_time(post_data)
        recovery_success_prob = self._calculate_recovery_success_probability(post_data)
        
        # Create recovery pattern
        pattern = RecoveryPattern(
            pattern_id=f"{biomarker_name}_{intervention_type.value}_recovery",
            intervention_type=intervention_type,
            baseline_trajectory=baseline_model,
            recovery_trajectory=recovery_model,
            transition_time=transition_time,
            recovery_rate=recovery_rate,
            recovery_success_probability=recovery_success_prob
        )
        
        self.recovery_patterns[pattern.pattern_id] = pattern
        
        logger.info(f"Recovery pattern analyzed successfully")
        logger.info(f"Recovery rate: {recovery_rate:.3f} units/{self.time_unit}")
        logger.info(f"Transition time: {transition_time:.1f} {self.time_unit}")
        logger.info(f"Success probability: {recovery_success_prob:.3f}")
        
        return pattern
    
    def predict_trajectory(self,
                          biomarker_name: str,
                          patient_id: str,
                          prediction_horizon: float = 168.0,
                          include_intervention: Optional[InterventionType] = None,
                          intervention_time: Optional[float] = None) -> Dict[str, Any]:
        """Predict biomarker trajectory for a patient"""
        
        logger.info(f"Predicting trajectory for {biomarker_name}, patient {patient_id}")
        
        # Get trajectory model
        trajectory_id = f"{biomarker_name}_linear"  # Default to linear
        if trajectory_id not in self.trajectory_models:
            raise ValueError(f"No trajectory model found for {biomarker_name}")
        
        trajectory_model = self.trajectory_models[trajectory_id]
        fitted_model = self.fitted_models[trajectory_id]
        
        # Get patient's current data
        patient_data = self._get_patient_data(patient_id, biomarker_name)
        
        if not patient_data:
            logger.warning(f"No data found for patient {patient_id}")
            return {}
        
        # Generate prediction timepoints
        current_time = max([dp.timepoint for dp in patient_data])
        future_times = np.linspace(current_time, current_time + prediction_horizon, 50)
        
        # Prepare features for prediction
        X_pred = self._prepare_prediction_features(
            future_times, patient_id, include_intervention, intervention_time
        )
        
        # Make predictions
        predictions = fitted_model.predict(X_pred)
        
        # Calculate prediction intervals
        prediction_intervals = self._calculate_prediction_intervals(
            fitted_model, X_pred, trajectory_model.model_type
        )
        
        # Apply intervention effects if specified
        if include_intervention and intervention_time is not None:
            predictions = self._apply_intervention_effects(
                predictions, future_times, intervention_time, 
                include_intervention, trajectory_model
            )
        
        prediction_result = {
            'patient_id': patient_id,
            'biomarker_name': biomarker_name,
            'prediction_times': future_times.tolist(),
            'predicted_values': predictions.tolist(),
            'prediction_intervals': prediction_intervals,
            'intervention_type': include_intervention.value if include_intervention else None,
            'intervention_time': intervention_time,
            'model_confidence': trajectory_model.fit_metrics.get('r2_score', 0.0)
        }
        
        logger.info(f"Trajectory prediction completed")
        logger.info(f"Prediction horizon: {prediction_horizon} {self.time_unit}")
        
        return prediction_result
    
    def validate_temporal_models(self) -> Dict[str, Dict[str, float]]:
        """Validate temporal models using time series cross-validation"""
        
        logger.info("Validating temporal models with time series CV")
        
        validation_results = {}
        
        for trajectory_id, trajectory_model in self.trajectory_models.items():
            logger.info(f"Validating model: {trajectory_id}")
            
            # Extract data
            biomarker_name = trajectory_model.biomarker_name
            times, values, patient_ids, interventions = self._extract_biomarker_data(biomarker_name)
            
            # Prepare features
            X = self._prepare_features(times, patient_ids, interventions)
            y = np.array(values)
            
            # Time series cross-validation
            tscv = TimeSeriesSplit(n_splits=5)
            cv_scores = []
            
            for train_idx, test_idx in tscv.split(X):
                X_train, X_test = X[train_idx], X[test_idx]
                y_train, y_test = y[train_idx], y[test_idx]
                
                # Fit model
                model, _ = self._fit_temporal_model(X_train, y_train, trajectory_model.model_type)
                
                # Predict
                y_pred = model.predict(X_test)
                
                # Calculate score
                score = r2_score(y_test, y_pred)
                cv_scores.append(score)
            
            # Calculate validation metrics
            validation_results[trajectory_id] = {
                'cv_r2_mean': np.mean(cv_scores),
                'cv_r2_std': np.std(cv_scores),
                'cv_r2_scores': cv_scores,
                'n_folds': len(cv_scores)
            }
            
            logger.info(f"CV R¬≤ score: {np.mean(cv_scores):.3f} ¬± {np.std(cv_scores):.3f}")
        
        return validation_results
    
    def generate_temporal_report(self) -> pd.DataFrame:
        """Generate comprehensive temporal modeling report"""
        
        logger.info("Generating temporal modeling report")
        
        report_data = []
        
        for trajectory_id, trajectory_model in self.trajectory_models.items():
            # Basic model info
            row = {
                'trajectory_id': trajectory_id,
                'biomarker_name': trajectory_model.biomarker_name,
                'trajectory_type': trajectory_model.trajectory_type.value,
                'model_type': trajectory_model.model_type.value,
                'r2_score': trajectory_model.fit_metrics.get('r2_score', np.nan),
                'rmse': trajectory_model.fit_metrics.get('rmse', np.nan),
                'mae': trajectory_model.fit_metrics.get('mae', np.nan),
                'n_parameters': len(trajectory_model.parameters)
            }
            
            # Intervention effects
            for intervention_type, effects in trajectory_model.intervention_effects.items():
                row[f'intervention_{intervention_type.value}_effect'] = effects.get('effect_size', np.nan)
                row[f'intervention_{intervention_type.value}_pvalue'] = effects.get('p_value', np.nan)
            
            # Recovery patterns
            recovery_pattern_id = f"{trajectory_model.biomarker_name}_treatment_recovery"
            if recovery_pattern_id in self.recovery_patterns:
                recovery = self.recovery_patterns[recovery_pattern_id]
                row['recovery_rate'] = recovery.recovery_rate
                row['transition_time'] = recovery.transition_time
                row['recovery_success_prob'] = recovery.recovery_success_probability
            
            report_data.append(row)
        
        report_df = pd.DataFrame(report_data)
        
        # Save report
        report_file = self.output_dir / "temporal_modeling_report.csv"
        report_df.to_csv(report_file, index=False)
        
        logger.info(f"Temporal modeling report saved to {report_file}")
        
        return report_df
    
    def save_models(self) -> None:
        """Save fitted models and metadata"""
        
        logger.info("Saving temporal models")
        
        # Save fitted models
        models_dir = self.output_dir / "models"
        models_dir.mkdir(exist_ok=True)
        
        for trajectory_id, model in self.fitted_models.items():
            model_file = models_dir / f"{trajectory_id}_model.joblib"
            joblib.dump(model, model_file)
        
        # Save trajectory models metadata
        trajectory_data = {}
        for trajectory_id, trajectory_model in self.trajectory_models.items():
            trajectory_data[trajectory_id] = {
                'trajectory_id': trajectory_model.trajectory_id,
                'biomarker_name': trajectory_model.biomarker_name,
                'trajectory_type': trajectory_model.trajectory_type.value,
                'model_type': trajectory_model.model_type.value,
                'parameters': trajectory_model.parameters,
                'fit_metrics': trajectory_model.fit_metrics,
                'intervention_effects': {
                    k.value: v for k, v in trajectory_model.intervention_effects.items()
                }
            }
        
        trajectory_file = self.output_dir / "trajectory_models.json"
        with open(trajectory_file, 'w') as f:
            json.dump(trajectory_data, f, indent=2, default=str)
        
        # Save recovery patterns
        recovery_data = {}
        for pattern_id, pattern in self.recovery_patterns.items():
            recovery_data[pattern_id] = {
                'pattern_id': pattern.pattern_id,
                'intervention_type': pattern.intervention_type.value,
                'transition_time': pattern.transition_time,
                'recovery_rate': pattern.recovery_rate,
                'recovery_success_probability': pattern.recovery_success_probability
            }
        
        recovery_file = self.output_dir / "recovery_patterns.json"
        with open(recovery_file, 'w') as f:
            json.dump(recovery_data, f, indent=2, default=str)
        
        logger.info(f"Models saved to {models_dir}")
        logger.info(f"Metadata saved to {self.output_dir}")
    
    # Private helper methods
    
    def _create_demo_temporal_data(self, biomarker_columns: List[str], n_patients: int = 50) -> pd.DataFrame:
        """Create demonstration temporal data"""
        
        np.random.seed(42)
        data = []
        
        for patient_id in range(n_patients):
            # Random patient characteristics
            baseline_severity = np.random.uniform(0.3, 0.9)
            recovery_rate = np.random.uniform(0.1, 0.3)
            intervention_time = np.random.uniform(24, 72) if np.random.random() > 0.3 else None
            
            # Generate timepoints (0 to 168 hours = 7 days)
            timepoints = np.sort(np.random.uniform(0, 168, np.random.randint(5, 20)))
            
            for timepoint in timepoints:
                row = {'patient_id': f'P{patient_id:03d}', 'timepoint': timepoint}
                
                # Generate biomarker values with temporal trends
                for biomarker in biomarker_columns:
                    if 'creatinine' in biomarker.lower():
                        # Kidney injury marker - increases then potentially recovers
                        baseline = np.random.uniform(0.8, 1.2)
                        if intervention_time and timepoint > intervention_time:
                            # Post-intervention recovery
                            recovery_progress = min(1.0, (timepoint - intervention_time) / 48)
                            value = baseline + baseline_severity * (1 - recovery_progress * recovery_rate)
                        else:
                            # Pre-intervention progression
                            value = baseline + baseline_severity * (timepoint / 72)
                        value += np.random.normal(0, 0.1)  # Noise
                    
                    elif 'teer' in biomarker.lower():
                        # Barrier function - decreases then recovers
                        baseline = np.random.uniform(800, 1200)
                        if intervention_time and timepoint > intervention_time:
                            recovery_progress = min(1.0, (timepoint - intervention_time) / 36)
                            value = baseline * (0.7 + 0.3 * recovery_progress * recovery_rate)
                        else:
                            value = baseline * (1 - 0.3 * timepoint / 48)
                        value += np.random.normal(0, 50)  # Noise
                    
                    else:
                        # Generic biomarker with temporal trend
                        baseline = np.random.uniform(50, 150)
                        trend = np.random.uniform(-0.5, 0.5) * timepoint / 168
                        value = baseline + trend + np.random.normal(0, 5)
                    
                    row[biomarker] = max(0, value)  # Ensure positive values
                
                # Add intervention information
                row['intervention_type'] = 'treatment' if intervention_time else 'none'
                row['intervention_time'] = intervention_time
                row['quality_score'] = np.random.uniform(0.8, 1.0)
                
                # Add clinical status
                row['aki_stage'] = min(3, int(baseline_severity * 3))
                row['recovery_status'] = 'improving' if intervention_time and timepoint > intervention_time else 'stable'
                
                data.append(row)
        
        return pd.DataFrame(data)
    
    def _extract_biomarker_data(self, biomarker_name: str) -> Tuple[List, List, List, List]:
        """Extract temporal data for a specific biomarker"""
        
        times, values, patient_ids, interventions = [], [], [], []
        
        for data_point in self.temporal_data:
            if biomarker_name in data_point.biomarker_values:
                times.append(data_point.timepoint)
                values.append(data_point.biomarker_values[biomarker_name])
                patient_ids.append(data_point.patient_id)
                interventions.append(data_point.intervention_status)
        
        return times, values, patient_ids, interventions
    
    def _prepare_features(self, times: List[float], patient_ids: List[str], 
                         interventions: Optional[List[InterventionType]] = None) -> np.ndarray:
        """Prepare feature matrix for modeling"""
        
        features = []
        
        # Convert patient IDs to numeric
        unique_patients = list(set(patient_ids))
        patient_map = {pid: i for i, pid in enumerate(unique_patients)}
        
        for i, time in enumerate(times):
            feature_row = [
                time,  # Time feature
                time**2,  # Quadratic time
                np.sin(2 * np.pi * time / 24),  # Circadian
                np.cos(2 * np.pi * time / 24),  # Circadian
                patient_map[patient_ids[i]]  # Patient ID
            ]
            
            # Add intervention features
            if interventions is not None:
                intervention = interventions[i]
                feature_row.extend([
                    1 if intervention == InterventionType.TREATMENT else 0,
                    1 if intervention == InterventionType.SURGERY else 0,
                    1 if intervention == InterventionType.MEDICATION else 0
                ])
            
            features.append(feature_row)
        
        return np.array(features)
    
    def _fit_temporal_model(self, X: np.ndarray, y: np.ndarray, 
                           model_type: ModelType) -> Tuple[Any, Dict[str, float]]:
        """Fit temporal model based on type"""
        
        if model_type == ModelType.RANDOM_FOREST:
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        elif model_type == ModelType.LINEAR_MIXED:
            model = Ridge(alpha=1.0)
        else:
            # Default to random forest
            model = RandomForestRegressor(n_estimators=50, random_state=42)
        
        # Fit model
        model.fit(X, y)
        
        # Calculate fit metrics
        y_pred = model.predict(X)
        fit_metrics = {
            'r2_score': r2_score(y, y_pred),
            'rmse': np.sqrt(mean_squared_error(y, y_pred)),
            'mae': np.mean(np.abs(y - y_pred)),
            'n_samples': len(y)
        }
        
        return model, fit_metrics
    
    def _calculate_confidence_intervals(self, model: Any, X: np.ndarray, y: np.ndarray,
                                      model_type: ModelType) -> Dict[str, Tuple[float, float]]:
        """Calculate confidence intervals for model predictions"""
        
        # Simple bootstrap approach for confidence intervals
        y_pred = model.predict(X)
        residuals = y - y_pred
        residual_std = np.std(residuals)
        
        return {
            'prediction': (y_pred.mean() - 1.96 * residual_std, 
                          y_pred.mean() + 1.96 * residual_std)
        }
    
    def _analyze_intervention_effects(self, biomarker_name: str, model: Any, 
                                    model_type: ModelType) -> Dict[InterventionType, Dict[str, float]]:
        """Analyze effects of different interventions"""
        
        intervention_effects = {}
        
        # For now, return placeholder intervention effects
        # In practice, this would analyze the model coefficients or feature importance
        
        if model_type == ModelType.RANDOM_FOREST and hasattr(model, 'feature_importances_'):
            # Analyze feature importance for intervention features
            feature_names = ['time', 'time2', 'sin_circadian', 'cos_circadian', 'patient_id',
                           'treatment', 'surgery', 'medication']
            
            if len(model.feature_importances_) >= len(feature_names):
                for i, intervention_type in enumerate([InterventionType.TREATMENT, 
                                                     InterventionType.SURGERY, 
                                                     InterventionType.MEDICATION]):
                    importance_idx = 5 + i  # Index of intervention features
                    if importance_idx < len(model.feature_importances_):
                        intervention_effects[intervention_type] = {
                            'effect_size': model.feature_importances_[importance_idx],
                            'p_value': 0.05,  # Placeholder
                            'confidence_interval': (0.0, model.feature_importances_[importance_idx] * 2)
                        }
        
        return intervention_effects
    
    def _extract_model_parameters(self, model: Any, model_type: ModelType) -> Dict[str, float]:
        """Extract interpretable parameters from fitted model"""
        
        parameters = {}
        
        if model_type == ModelType.LINEAR_MIXED and hasattr(model, 'coef_'):
            parameters = {f'coef_{i}': coef for i, coef in enumerate(model.coef_)}
            if hasattr(model, 'intercept_'):
                parameters['intercept'] = model.intercept_
        elif model_type == ModelType.RANDOM_FOREST:
            parameters = {
                'n_estimators': model.n_estimators,
                'max_depth': model.max_depth,
                'feature_importance_mean': np.mean(model.feature_importances_)
            }
        
        return parameters
    
    def _split_intervention_data(self, biomarker_name: str, 
                               intervention_type: InterventionType) -> Tuple[Tuple, Tuple]:
        """Split data into pre and post intervention periods"""
        
        pre_times, pre_values = [], []
        post_times, post_values = [], []
        
        for data_point in self.temporal_data:
            if (biomarker_name in data_point.biomarker_values and 
                data_point.intervention_status == intervention_type and
                data_point.intervention_time is not None):
                
                if data_point.timepoint <= data_point.intervention_time:
                    pre_times.append(data_point.timepoint)
                    pre_values.append(data_point.biomarker_values[biomarker_name])
                else:
                    post_times.append(data_point.timepoint - data_point.intervention_time)
                    post_values.append(data_point.biomarker_values[biomarker_name])
        
        return (pre_times, pre_values), (post_times, post_values)
    
    def _fit_baseline_trajectory(self, pre_data: Tuple, biomarker_name: str) -> TrajectoryModel:
        """Fit baseline trajectory before intervention"""
        
        times, values = pre_data
        
        # Simple linear fit for baseline
        if len(times) >= 2:
            # Use numpy polyfit for simpler typing
            coeffs = np.polyfit(times, values, 1)
            slope = float(coeffs[0])
            intercept = float(coeffs[1])
            
            # Calculate R¬≤
            y_pred = slope * np.array(times) + intercept
            ss_res = np.sum((np.array(values) - y_pred) ** 2)
            ss_tot = np.sum((np.array(values) - np.mean(values)) ** 2)
            r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0
            
            return TrajectoryModel(
                trajectory_id=f"{biomarker_name}_baseline",
                biomarker_name=biomarker_name,
                trajectory_type=TrajectoryType.LINEAR,
                model_type=ModelType.LINEAR_MIXED,
                parameters={'slope': slope, 'intercept': intercept},
                fit_metrics={'r2_score': float(r_squared), 'p_value': 0.05},
                confidence_intervals={'slope': (slope - 0.1 * abs(slope), slope + 0.1 * abs(slope))},
                intervention_effects={}
            )
        
        # Return dummy model if insufficient data
        return TrajectoryModel(
            trajectory_id=f"{biomarker_name}_baseline_dummy",
            biomarker_name=biomarker_name,
            trajectory_type=TrajectoryType.LINEAR,
            model_type=ModelType.LINEAR_MIXED,
            parameters={'slope': 0.0, 'intercept': 0.0},
            fit_metrics={'r2_score': 0.0, 'p_value': 1.0},
            confidence_intervals={'slope': (0.0, 0.0)},
            intervention_effects={}
        )
    
    def _fit_recovery_trajectory(self, post_data: Tuple, biomarker_name: str) -> TrajectoryModel:
        """Fit recovery trajectory after intervention"""
        
        times, values = post_data
        
        # Exponential recovery fit
        if len(times) >= 3:
            # Try exponential recovery: y = a * exp(-b*t) + c
            try:
                # Use numpy polyfit for simple linear fit
                coeffs = np.polyfit(times, values, 1)
                slope = float(coeffs[0])
                intercept = float(coeffs[1])
                
                # Calculate R¬≤
                y_pred = slope * np.array(times) + intercept
                ss_res = np.sum((np.array(values) - y_pred) ** 2)
                ss_tot = np.sum((np.array(values) - np.mean(values)) ** 2)
                r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0
                
                return TrajectoryModel(
                    trajectory_id=f"{biomarker_name}_recovery",
                    biomarker_name=biomarker_name,
                    trajectory_type=TrajectoryType.RECOVERY,
                    model_type=ModelType.LINEAR_MIXED,
                    parameters={'slope': slope, 'intercept': intercept},
                    fit_metrics={'r2_score': float(r_squared), 'p_value': 0.05},
                    confidence_intervals={'slope': (slope - 0.1 * abs(slope), slope + 0.1 * abs(slope))},
                    intervention_effects={}
                )
            except Exception:
                pass
        
        # Return dummy model if insufficient data or fitting failed
        return TrajectoryModel(
            trajectory_id=f"{biomarker_name}_recovery_dummy",
            biomarker_name=biomarker_name,
            trajectory_type=TrajectoryType.RECOVERY,
            model_type=ModelType.LINEAR_MIXED,
            parameters={'slope': 0.0, 'intercept': 0.0},
            fit_metrics={'r2_score': 0.0, 'p_value': 1.0},
            confidence_intervals={'slope': (0.0, 0.0)},
            intervention_effects={}
        )
    
    def _calculate_recovery_rate(self, post_data: Tuple) -> float:
        """Calculate recovery rate from post-intervention data"""
        
        times, values = post_data
        
        if len(times) >= 2:
            # Simple slope calculation using numpy
            coeffs = np.polyfit(times, values, 1)
            slope = float(coeffs[0])
            return abs(slope)  # Recovery rate as absolute change per time unit
        
        return 0.0
    
    def _estimate_transition_time(self, post_data: Tuple) -> float:
        """Estimate time to reach 50% recovery"""
        
        times, values = post_data
        
        if len(times) >= 3:
            initial_value = values[0]
            final_value = values[-1]
            halfway_value = initial_value + 0.5 * (final_value - initial_value)
            
            # Find time closest to halfway value
            closest_idx = np.argmin(np.abs(np.array(values) - halfway_value))
            return times[closest_idx]
        
        return np.mean(times) if times else 0.0
    
    def _calculate_recovery_success_probability(self, post_data: Tuple) -> float:
        """Calculate probability of successful recovery"""
        
        times, values = post_data
        
        if len(values) >= 2:
            # Simple metric: improvement over time
            improvement = (values[-1] - values[0]) / values[0] if values[0] != 0 else 0
            # Convert to probability (sigmoid-like)
            return 1 / (1 + np.exp(-improvement * 5))
        
        return 0.5
    
    def _get_patient_data(self, patient_id: str, biomarker_name: str) -> List[TemporalDataPoint]:
        """Get all data points for a specific patient and biomarker"""
        
        patient_data = []
        for data_point in self.temporal_data:
            if (data_point.patient_id == patient_id and 
                biomarker_name in data_point.biomarker_values):
                patient_data.append(data_point)
        
        return sorted(patient_data, key=lambda x: x.timepoint)
    
    def _prepare_prediction_features(self, times: np.ndarray, patient_id: str,
                                   intervention_type: Optional[InterventionType],
                                   intervention_time: Optional[float]) -> np.ndarray:
        """Prepare features for trajectory prediction"""
        
        features = []
        
        # Get patient index (simplified)
        patient_idx = hash(patient_id) % 100  # Simple patient encoding
        
        for time in times:
            feature_row = [
                time,  # Time feature
                time**2,  # Quadratic time
                np.sin(2 * np.pi * time / 24),  # Circadian
                np.cos(2 * np.pi * time / 24),  # Circadian
                patient_idx  # Patient ID encoding
            ]
            
            # Add intervention features
            if intervention_time is not None:
                post_intervention = 1 if time > intervention_time else 0
                feature_row.extend([
                    post_intervention if intervention_type == InterventionType.TREATMENT else 0,
                    post_intervention if intervention_type == InterventionType.SURGERY else 0,
                    post_intervention if intervention_type == InterventionType.MEDICATION else 0
                ])
            else:
                feature_row.extend([0, 0, 0])
            
            features.append(feature_row)
        
        return np.array(features)
    
    def _calculate_prediction_intervals(self, model: Any, X_pred: np.ndarray,
                                      model_type: ModelType) -> List[Tuple[float, float]]:
        """Calculate prediction intervals"""
        
        predictions = model.predict(X_pred)
        
        # Simple approach: use training residuals to estimate uncertainty
        if model_type == ModelType.RANDOM_FOREST:
            # Use tree variance for uncertainty
            tree_predictions = np.array([tree.predict(X_pred) for tree in model.estimators_])
            prediction_std = np.std(tree_predictions, axis=0)
        else:
            # Default uncertainty
            prediction_std = np.std(predictions) * 0.1
        
        intervals = []
        for i, pred in enumerate(predictions):
            if isinstance(prediction_std, np.ndarray):
                std = float(prediction_std[i])
            else:
                std = float(prediction_std)
            intervals.append((pred - 1.96 * std, pred + 1.96 * std))
        
        return intervals
    
    def _apply_intervention_effects(self, predictions: np.ndarray, times: np.ndarray,
                                  intervention_time: float, intervention_type: InterventionType,
                                  trajectory_model: TrajectoryModel) -> np.ndarray:
        """Apply intervention effects to predictions"""
        
        modified_predictions = predictions.copy()
        
        # Get intervention effect if available
        if intervention_type in trajectory_model.intervention_effects:
            effect = trajectory_model.intervention_effects[intervention_type].get('effect_size', 0)
            
            # Apply effect post-intervention
            post_intervention_mask = times > intervention_time
            
            if np.any(post_intervention_mask):
                # Apply exponential decay of intervention effect
                time_since_intervention = times[post_intervention_mask] - intervention_time
                decay_factor = np.exp(-time_since_intervention / 48)  # 48-hour half-life
                
                modified_predictions[post_intervention_mask] += effect * decay_factor
        
        return modified_predictions


def create_demo_temporal_modeling():
    """Create demonstration of dynamic biomarker modeling"""
    
    print("\nüï∞Ô∏è  DYNAMIC BIOMARKER MODELING DEMONSTRATION")
    print("=" * 60)
    
    # Initialize modeler
    modeler = DynamicBiomarkerModeler(
        data_dir=Path("demo_outputs"),
        output_dir=Path("demo_outputs/temporal")
    )
    
    print("üìä Loading temporal biomarker data...")
    
    # Define biomarkers to model
    biomarkers = ['serum_creatinine', 'teer_resistance', 'inflammatory_score']
    
    # Load temporal data
    df = modeler.load_temporal_data(
        temporal_file=Path("demo_temporal.csv"),
        biomarker_columns=biomarkers,
        time_column="timepoint",
        patient_column="patient_id"
    )
    
    print(f"   Loaded {len(modeler.temporal_data)} temporal measurements")
    print(f"   Biomarkers: {biomarkers}")
    print(f"   Time range: {df['timepoint'].min():.1f} - {df['timepoint'].max():.1f} hours")
    
    print("\nüìà Fitting trajectory models...")
    
    # Fit trajectory models for each biomarker
    trajectory_models = {}
    
    for biomarker in biomarkers:
        print(f"   Fitting model for {biomarker}...")
        
        model = modeler.fit_trajectory_model(
            biomarker_name=biomarker,
            trajectory_type=TrajectoryType.LINEAR,
            model_type=ModelType.RANDOM_FOREST,
            include_interventions=True
        )
        
        trajectory_models[biomarker] = model
        print(f"      R¬≤ score: {model.fit_metrics['r2_score']:.3f}")
        print(f"      RMSE: {model.fit_metrics['rmse']:.3f}")
    
    print(f"\nüîÑ Analyzing recovery patterns...")
    
    # Analyze recovery patterns
    recovery_patterns = {}
    
    for biomarker in biomarkers:
        print(f"   Analyzing recovery for {biomarker}...")
        
        pattern = modeler.analyze_recovery_patterns(
            biomarker_name=biomarker,
            intervention_type=InterventionType.TREATMENT
        )
        
        if pattern:
            recovery_patterns[biomarker] = pattern
            print(f"      Recovery rate: {pattern.recovery_rate:.3f}")
            print(f"      Transition time: {pattern.transition_time:.1f} hours")
            print(f"      Success probability: {pattern.recovery_success_probability:.3f}")
    
    print(f"\nüîÆ Generating trajectory predictions...")
    
    # Make predictions for sample patients
    sample_patients = ['P001', 'P002', 'P003']
    predictions = {}
    
    for patient_id in sample_patients:
        patient_predictions = {}
        
        for biomarker in biomarkers:
            # Predict without intervention
            pred_baseline = modeler.predict_trajectory(
                biomarker_name=biomarker,
                patient_id=patient_id,
                prediction_horizon=72.0  # 3 days
            )
            
            # Predict with treatment intervention
            pred_treatment = modeler.predict_trajectory(
                biomarker_name=biomarker,
                patient_id=patient_id,
                prediction_horizon=72.0,
                include_intervention=InterventionType.TREATMENT,
                intervention_time=24.0  # Intervention at 24 hours
            )
            
            patient_predictions[biomarker] = {
                'baseline': pred_baseline,
                'treatment': pred_treatment
            }
        
        predictions[patient_id] = patient_predictions
    
    print(f"      Generated predictions for {len(sample_patients)} patients")
    
    print(f"\n‚úÖ Validating temporal models...")
    
    # Validate models
    validation_results = modeler.validate_temporal_models()
    
    print(f"      Validation completed for {len(validation_results)} models")
    for model_id, results in validation_results.items():
        print(f"      {model_id}: CV R¬≤ = {results['cv_r2_mean']:.3f} ¬± {results['cv_r2_std']:.3f}")
    
    print(f"\nüìã Generating temporal modeling report...")
    
    # Generate report
    report_df = modeler.generate_temporal_report()
    modeler.save_models()
    
    print(f"\nüìä Temporal Modeling Summary:")
    print(f"   Trajectory models: {len(trajectory_models)}")
    print(f"   Recovery patterns: {len(recovery_patterns)}")
    print(f"   Patient predictions: {len(predictions)}")
    print(f"   Average model R¬≤: {report_df['r2_score'].mean():.3f}")
    
    if not report_df.empty:
        print(f"\nüéØ Model Performance:")
        for _, row in report_df.iterrows():
            print(f"   {row['biomarker_name']}: R¬≤={row['r2_score']:.3f}, RMSE={row['rmse']:.3f}")
    
    print(f"\n‚úÖ Dynamic biomarker modeling demonstration completed!")
    print(f"üìÅ Results saved to: demo_outputs/temporal/")
    
    return modeler, trajectory_models, recovery_patterns, predictions


if __name__ == "__main__":
    create_demo_temporal_modeling()
